import tensorflow as tf
import tensorflow.feature_column as feature_column
from tensorflow.estimator import DNNClassifier
from fast_predict2 import FastPredict

# Example to learn a XOR function
# Use "python classifierestimator.py": Train and test the model. The model will be reused after the train
# Use rm -rf model to delete the current model, a new one will be created automatically

# TODO: Remove tf.constant() calls?

def input_fn(n_repetitions = 1) -> tf.data.Dataset:
    """
    Returns the XOR function dataset

    Args:
        n_repetitions: Number of times to repeat the XOR function
    """

    # The inputs. Each dict key is a dataset column. Each index is ONE column value. The array is the "batch" of inputs to train / estimate
    xor_x = {
        'x1': tf.constant( [ 0 , 1 , 0 , 1 ] ),
        'x2': tf.constant( [ 0 , 0 , 1 , 1 ] )
    }

    # The expected outputs ("labels"). Each index is ONE output. The array is the output "batch"
    xor_y =  tf.constant( [ 0 , 1 , 1 , 0 ] )

    # The dataset
    ds = tf.data.Dataset.from_tensors( (xor_x,xor_y) )

    # If we are training, we will need a lot of samples, not only four. So, repeat the 4 values
    if n_repetitions > 1:
        ds = ds.repeat(n_repetitions)
    
    return ds


# dataset input interesting columns (all!)
x1_column = feature_column.numeric_column( 'x1' )
x2_column = feature_column.numeric_column( 'x2' )

# The model
estimator = DNNClassifier(
    hidden_units=[6, 6],
    feature_columns=[x1_column, x2_column],
    model_dir='./model'
)

def accuracy() -> float:
    """
    Returns the current ratio of succesfully predicted outputs of XOR function: 0.0 = 0%, 1.0 = 100%
    """

    # Estimate a dataset with no repetitions (all the possible XOR inputs)
    result = estimator.evaluate( input_fn=input_fn )
    print("Evaluation: ", result)
    return result['accuracy']


# Train until we get a 100% accuracy. Train 1000 times all the inputs on each call
while accuracy() < 1.0:
    estimator.train( input_fn=lambda:input_fn(1000) )

# The oficial way to make predictions with estimators:
# def single_eval_input_dataset( x1 : int, x2 : int ) -> tf.data.Dataset:
#     """
#     Returns a dataset with a single input for the XOR (without the output!)

#     Args:
#         x1, x2: XOR inputs
#     """

#     xor_x = {
#         'x1': tf.constant( [ x1 ] ) ,
#         'x2': tf.constant( [ x2 ] )
#     }
#     return tf.data.Dataset.from_tensors(xor_x)


# def print_eval(x1 : int, x2 : int):
#     """
#     Print the output prediction for a XOR input

#     Args:
#         x1, x2: XOR inputs
#     """

#     result = estimator.predict( input_fn=lambda:single_eval_input_dataset(x1,x2) )
#     #print(result)
#     for r in result:
#         print('Input:', x1, x2)
#         print('Output:', r['class_ids'])

# estimator.predict is SLOOOOWWWWW with Tensorflow 1.12, because it recreates the graph with each call.
# I have tried https://stackoverflow.com/questions/49966447/keep-the-tensorflow-estimator-in-memory-while-waiting-for-live-prediction-inputs 
# with no success
# https://github.com/marcsto/rl/blob/master/src/fast_predict2.py works :

def inference_input_fn(generator):
    """
    Returns a function that returns the input Dataset for the "generator" generator. Yes, really.

    Needed to use with FastPredict.
    Args:
        generator: Tensorflow Generator generated by FastPredict. I suspect it returns the next batch of inputs
    """

    def _inner_input_fn():
        """
        Closure function returned by inference_input_fn with the dataset for the next batch of inputs (I think)
        """
        # All comments on this funcion are suspicions, not facts

        # Create next input from the generator
        dataset = tf.data.Dataset().from_generator( generator, output_types=(tf.int32 , tf.int32) ).batch(1)

        # Get the next input batch
        iterator = dataset.make_one_shot_iterator()
        features = iterator.get_next()

        # create and return the equivalent features dictonary
        feature_dict = dict(zip( ['x1', 'x2'], features))
        return feature_dict

    return _inner_input_fn

# FastPredict: The tool to avoid to rebuild the graph for each estimator.predict call
fast_predictor = FastPredict(estimator, inference_input_fn )

def print_eval(x1 : int, x2 : int):
    """
    Print the output prediction for a XOR input

    Args:
        x1, x2: XOR inputs
    """

    result = fast_predictor.predict( ( [x1] , [x2] ) )
    # TODO: "result" contains TWO equal results... I don't know why
    #print(result)
    #for r in result:
    r = result[0]
    print('Input:', x1, x2)
    print('Output:', r['class_ids'])

print("Results")
print_eval(0, 0)
print_eval(0, 1)
print_eval(1, 0)
print_eval(1, 1)

fast_predictor.close()